{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지도학습과 비지도학습\n",
    "- 학습 : 데이터를 특별한 알고리즘에 적용해 머신러닝 모델을 정의된 문제에 최적화(y*) 과정을 의미\n",
    "\n",
    "## 지도학습(Supervised Learning)\n",
    "- 정답을 알려주면서 진행되는 학습\n",
    "- 정답, 실제값, 레이블, 타깃, 클래스, y값 : 동일한 의미\n",
    "- 머신러닝 모델을 통해 예측된 값을 '예측값, 분류값, y^' 등으로 표현\n",
    "- 지도학습의 예로는 분류(classification)와 회귀(regression)이 대표적\n",
    "\n",
    "## 비지도학습(Unsupervised Learning)\n",
    "- 정답(label)이 없이 진행하는 학습\n",
    "- 데이터 자체에서 패턴을 찾아낼 때 사용\n",
    "- 예로는 군집화와 차원축소가 대표적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 분류와 회귀\n",
    "- 분류와 회귀의 큰 차이점은 데이터가 입력되었을 때 분류는 분리된 값으로 예측하고, 회귀는 연속된 값으로 예측한다.\n",
    "\n",
    "## 분류(Classification)\n",
    "- 분류는 데이터가 입력되었을 때 지도학습을 통해 미리 학습된 label 중 하나 또는 여러 개의 label로 예측하는 것\n",
    "\n",
    "### 이진분류\n",
    "- 둘 중 하나의 값으로 분류하는 경우 (sigmoid)\n",
    "\n",
    "### 다중분류\n",
    "- 여러 개의 분류값 중에서 하나의 값으로 예측하는 경우 (softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> deeplearning에서 sigmoid와 softmax가 많이 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 과대적합(Overfitting)과 과소적합(underfitting)\n",
    "- 데이터에서 충분히 특징을 찾아내지 못하고 머신러닝 모델 학습을 할 경우, 모델이 과소적합되기 쉽고(tr 예측률보다 test 예측률이 높게 나온다.)\n",
    "- 필요 이상의 특징으로 학습할 경우 모델이 과대적합되기 쉽다.\n",
    "\n",
    "## 과소적합\n",
    "- 보통 테스트데이터 뿐만 아니라 학습데이터에 대해서도 정확도가 낮게 나올 경우, 과소적합된 모델일 가능성이 높음\n",
    "\n",
    "## 과대적합\n",
    "- 학습데이터와의 데이터에는 정확도가 낮게 나오는 모델\n",
    "- 데이터의 특징들의 수치값을 정규화함으로써 특정 특징에 의한 편향(bias)을 줄이는 것도 과대적합을 피하는 좋은 방법이다.\n",
    "- y = ax + b(b를 조점함으로써 편향 조절)\n",
    "- 딥러닝같은 경우 조기종료(early stopping), 드롭아웃(drop out)을 사용해 과대적합을 피할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> drop out : 컬럼 수 줄이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 혼동행렬(confusion matrix)\n",
    "- 모델의 성능을 평가할 때 사용되는 지표\n",
    "- 실제값과 예측값을 비교하여 어느정도 일치하는지 파악\n",
    "- 모델의 성능은 이 혼동행렬을 기반으로 단 하나의 수치로 표현 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예측값에서 클래스 : 행,   \n",
    "> 정오표에서 실제값으로 얘기한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신러닝 모델의 성능 평가\n",
    "- TP(True Positive) : 맞는 것을 올바르게 예측한 것 \n",
    "- TN(True Negative) : 틀린 것을 올바르게 예측한 것 ~ 아닌 것을 아니라고 예측!\n",
    "- FP(False Positive) : 틀린 것을 잘못 예측한 것\n",
    "- FN(False Negative) : 맞는 것을 잘못 예측한 것   \n",
    "> OVR : one versus rest    \n",
    "### 정확도(Accuracy)\n",
    "- 가장 일반적인 모델성능 평가지표\n",
    "- 혼동행렬에서는 TP를 전체 셀로 나눈 값에 해당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.75 %\n"
     ]
    }
   ],
   "source": [
    "print((9 + 15 + 24 + 15) / (9 + 1 + 1 + 15 + 3 + 1 + 5 + 24 + 1 + 4 + 1 + 15) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도(precision)\n",
    "- 각 모델들의 예측값이 얼마나 정확하게 예측됐는가를 나타내는 지표\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 모델의 정확도 : 69.0 %\n",
      "B 모델의 정확도 : 71.0 %\n"
     ]
    }
   ],
   "source": [
    "# 두가지 모델의 정확도\n",
    "print(f'A 모델의 정확도 : {(9+60)/100*100} %')\n",
    "print(f'B 모델의 정확도 : {(1+70)/100*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 모델의 암환자 정밀도 : 0.23076923076923078\n",
      "B 모델의 암환자 정밀도 : 0.047619047619047616\n",
      "A 모델의 일반환자 정밀도 : 0.9836065573770492\n",
      "B 모델의 일반환자 정밀도 : 0.8860759493670886\n"
     ]
    }
   ],
   "source": [
    "# 2가지 모델의 정밀도 : TP/ (TP + FP)\n",
    "print(f'A 모델의 암환자 정밀도 : {9/(9+30)}')\n",
    "print(f'B 모델의 암환자 정밀도 : {1/(1+20)}')\n",
    "print(f'A 모델의 일반환자 정밀도 : {60/(60+1)}')\n",
    "print(f'B 모델의 일반환자 정밀도 : {70/(70+9)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 암환자의 예측력의 정밀도는 A모델이 더 우수하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 재현율(Recall)\n",
    "- 실제값 중에서 모델이 검출한 실제값의 비율을 나타내는 지표\n",
    "- 재현율 = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 모델의 암환자 재현율 : 0.9\n",
      "B 모델의 암환자 재현율 : 0.1\n",
      "A 모델의 일반환자 재현율 : 0.6666666666666666\n",
      "B 모델의 일반환자 재현율 : 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "print(f'A 모델의 암환자 재현율 : {9/(9+1)}')\n",
    "print(f'B 모델의 암환자 재현율 : {1/(1+9)}')\n",
    "print(f'A 모델의 일반환자 재현율 : {60/(60+30)}')\n",
    "print(f'B 모델의 일반환자 재현율 : {70/(70+20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 암환자 재현율을 기준으로, A Model이 더 우수하다. 일반환자의 경우 B Model이 우수하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 점수(F1 Score)\n",
    "- 정밀도도 중요하고 재현율도 중요한데 어떤 것을 선택할까? > 두 값을 조화평균 내서 F1 Score 구하기\n",
    "- 조화평균 = 2 * a * b / (a + b)\n",
    "- F1 Score = 2 * 재현율 * 정밀도 / (재현율 + 정밀도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 모델의 암환자 F1 Score : 0.3673469387755102\n"
     ]
    }
   ],
   "source": [
    "print(f'A 모델의 암환자 F1 Score : {2*(9/39)*(9/10)/(9/39+9/10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B 모델의 암환자 F1 Score : 0.06451612903225806\n"
     ]
    }
   ],
   "source": [
    "print(f'B 모델의 암환자 F1 Score : {2*(1/21)*(1/10)/(1/21+1/10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 일반적으로 지표는 소수점 3째자리까지 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### k-폴드 교차검증(k-fold cross validation)\n",
    "- 모든 학습데이터를 한 번씩 검증데이터로 활용해, 검증데이터가 한쪽에 편향되지 않아서 분리하지 않고도 학습데이터에 대한 전반적인 검증 정확도를 구할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> k가 4일 때 4*4 행렬을 그려서 4가지 경우의 수로 train/test 데이터셋을 검증한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c34e8390e776d2ee205b71ed5a6130fee3cef8da5e87e926ce18e14f4a070d72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
