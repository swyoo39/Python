{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL이 ML보다 뛰어난 부분 : Image, 문장 처리   \n",
    "- Image : CNN\n",
    "- 문장 : RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data/preview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "- ML의 한 종류\n",
    "- 여러 층(은닉층)을 가진 신경망을 사용해 머신러닝을 수행하는 것\n",
    "- 이미지 인식, 음성 인식, 자연어 처리 등의 다양한 분야에 활용\n",
    "- 1980년대부터 있었지만, 현대에 와서 컴퓨터 성능이 좋아지고 비즈니스적으로 성공하면서 주목받기 시작함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning과 Machine Learning의 차이점\n",
    "- 가장 큰 차이점 : Feature(특징) 추출\n",
    "- Deep Learning은 스스로 학습을 하기에 Machine Learning보다 많은 Data가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스마트폰을 구매할까?\n",
    "- 구매의 경우 y = 1, 아니면 y = 0\n",
    "\n",
    "입력의 요인들 정리\n",
    "- X1 : 이번달의 수입은 충분한가?\n",
    "- X2 : 최신 기능을 탑재했는가?\n",
    "- X3 : 기존의 스마트폰에 문제가 있는가?\n",
    "\n",
    "x1, x2, x3의 가중치를 w1, w2, w3로 하였을 때 예상되는 조건들\n",
    "- 부자인 경우 w1=1, w2=3, w3=2\n",
    "- 스마트폰에 문제가 생긴 사람의 가중치는 w1=2, w2=1, w3=8\n",
    "- 정기적으로 스마트폰을 구매하는 사람의 가중치는 w1=1, w2=8, w3=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순전파(Forward Propagation)\n",
    "- 왼쪽에서 오른쪽으로 흘러가는 과정\n",
    "- 순전파에 의해 딥러닝의 출력값(y^)이 결정된다. 정답은 y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수(Loss Function)\n",
    "- 출력값과 정답의 차이\n",
    "- 출력값과 정답이 일치할수록 손실함수의 값은 작아진다.\n",
    "- 회귀에서 평균제곱오차(Mean Squared Error)를 사용\n",
    "- 분류에서는 크로스 엔트로피(Cross Entropy)를 사용\n",
    "- 매개변수(w, b)를 조절해서 손실함수의 값을 최저로 만드는 과정을 최적화(Optimization)이라 한다. '경사 하강법'\n",
    "- 최적화 과정은 Optimizer를 통해 이뤄지며,    \n",
    "Optimizer는 역전파(back Propagation) 과정을 수행하여 딥러닝 모델의 매개변수를 최적화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화(Optimization)\n",
    "- 대표적인 방법은 경사 하강법\n",
    "- 반복적으로 손실함수에 대한 모델 매개변수의 기울기를 구한 후   \n",
    "그 미분값의 반대방향으로 매개변수를 조절해 나가면 결국 최저 손실함수값에 도달(수렴)한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파(Back Propagation)\n",
    "- Optimizer는 손실함수의 값을 최소화하기 위해 역전파를 사용해 딥러닝 모델의 모든 매개변수를 변경한다.\n",
    "- 손실함수의 값ㅇ르 최소화하는 것은 정답과 예측값의 차이를 최소화하는 것이며 에러율을 최저로 줄인다는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝의 과대적합(Overfitting)\n",
    "### 드롭아웃(Drop Out)\n",
    "- 매개변수 중 일정량을 학습 중간마다 무작위로 사용하지 않는 방법\n",
    "- 드롭아웃을 사용하면 모델에 앙상블 효과를 준다.\n",
    "\n",
    "### 조기종료(Early Stopping)\n",
    "- 무조건 반복횟수를 높이면 학습시간이 길어져서 학습데이터만 성능이 좋은 현상이 발생.\n",
    "- 학습데이터로만 모델의 매개변수를 조정하고 검증데이터로 모델의 정확도를 측정한다.\n",
    "- 조기종료는 학습횟수에 따라 검증정확도가 꾸준히 떨어지는 시점이 발견되면 즉시 학습을 중단하고 그 전의 최고점을 사용한다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
