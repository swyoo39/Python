{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  rank\n",
       "0      0  380.0  3.21     3\n",
       "1      1  660.0  3.67     3\n",
       "2      1  800.0  4.00     1\n",
       "3      1  640.0  3.19     4\n",
       "4      0  520.0  2.33     4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/gpascore.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 미국 대학   \n",
    "admit : 합격/불합격,   \n",
    "gre : 영어 성적,   \n",
    "gpa : 학점,    \n",
    "rank : 지원한 대학원 등급   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing(전처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit    0\n",
       "gre      1\n",
       "gpa      0\n",
       "rank     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 처리\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 데이터 삭제\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# 결측치 데이터 치환\n",
    "# data.fillna(100, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit    0\n",
       "gre      0\n",
       "gpa      0\n",
       "rank     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    158\n",
       "3    129\n",
       "4     71\n",
       "1     67\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rank의 종류 파악\n",
    "data['rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(data['rank'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 : 800.0\n",
      "최소 : 220.0\n"
     ]
    }
   ],
   "source": [
    "# 영어 점수의 최소, 최대값\n",
    "print('최대 :', data.gre.max())\n",
    "print('최소 :', data.gre.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre   gpa  rank\n",
       "0  380.0  3.21     3\n",
       "1  660.0  3.67     3\n",
       "2  800.0  4.00     1\n",
       "3  640.0  3.19     4\n",
       "4  520.0  2.33     4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Data\n",
    "x = data[['gre', 'gpa', 'rank']]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: admit, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Data\n",
    "y = data['admit']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gre     425\n",
       "gpa     425\n",
       "rank    425\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 입력층 3개, gre/gpa/rank   \n",
    "> 출력층 1개, admit : 0과 1의 이진분류, sigmoid 함수 활용   \n",
    "> 입력층을 제외하고 1개 층을 가지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Deep Learning Model 만들기 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.layers.InputLayer(input_shape=(3,))\n",
    "hidden_layer = keras.layers.Dense(256, activation='tanh')\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 10:57:49.717927: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# sequential, add할 때마다 층이 하나씩 쌓인다.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        input_layer,\n",
    "        hidden_layer,\n",
    "        output_layer\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy') \n",
    "# sparse는 입력값이 실수라 쓸 수 없다.\n",
    "# binary_crossentropy : 분류 및 확률 예측\n",
    "# metrics : 모델의 평가 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시키기\n",
    "# 현재 data가 pandas에 들어있음\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6118\n",
      "Epoch 2/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6518\n",
      "Epoch 3/110\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.6071\n",
      "Epoch 4/110\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.5976\n",
      "Epoch 5/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6494\n",
      "Epoch 6/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6047\n",
      "Epoch 7/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.6329\n",
      "Epoch 8/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6353\n",
      "Epoch 9/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6094\n",
      "Epoch 10/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5529\n",
      "Epoch 11/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5741\n",
      "Epoch 12/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6024\n",
      "Epoch 13/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6118\n",
      "Epoch 14/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6071\n",
      "Epoch 15/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6141\n",
      "Epoch 16/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6541\n",
      "Epoch 17/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6494\n",
      "Epoch 18/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6729\n",
      "Epoch 19/110\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6251 - accuracy: 0.6612\n",
      "Epoch 20/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6635\n",
      "Epoch 21/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6471\n",
      "Epoch 22/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6329\n",
      "Epoch 23/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6447\n",
      "Epoch 24/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.6612\n",
      "Epoch 25/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6400\n",
      "Epoch 26/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6565\n",
      "Epoch 27/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6235\n",
      "Epoch 28/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6471\n",
      "Epoch 29/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6282\n",
      "Epoch 30/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6494\n",
      "Epoch 31/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6212\n",
      "Epoch 32/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.6471\n",
      "Epoch 33/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6588\n",
      "Epoch 34/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.5600\n",
      "Epoch 35/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.6847\n",
      "Epoch 36/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6259\n",
      "Epoch 37/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6282\n",
      "Epoch 38/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6353\n",
      "Epoch 39/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6541\n",
      "Epoch 40/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.5976\n",
      "Epoch 41/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.5953\n",
      "Epoch 42/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.5365\n",
      "Epoch 43/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.5765\n",
      "Epoch 44/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6353\n",
      "Epoch 45/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6118\n",
      "Epoch 46/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6047\n",
      "Epoch 47/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6212\n",
      "Epoch 48/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6353\n",
      "Epoch 49/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6118\n",
      "Epoch 50/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6471\n",
      "Epoch 51/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6024\n",
      "Epoch 52/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.5600\n",
      "Epoch 53/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6541\n",
      "Epoch 54/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6447\n",
      "Epoch 55/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6188\n",
      "Epoch 56/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6118\n",
      "Epoch 57/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.6118\n",
      "Epoch 58/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6306\n",
      "Epoch 59/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6376\n",
      "Epoch 60/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6376\n",
      "Epoch 61/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6141\n",
      "Epoch 62/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6400\n",
      "Epoch 63/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.5953\n",
      "Epoch 64/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6424\n",
      "Epoch 65/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6541\n",
      "Epoch 66/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6447\n",
      "Epoch 67/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6494\n",
      "Epoch 68/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.5882\n",
      "Epoch 69/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.5906\n",
      "Epoch 70/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6518\n",
      "Epoch 71/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6424\n",
      "Epoch 72/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6565\n",
      "Epoch 73/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6447\n",
      "Epoch 74/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6141\n",
      "Epoch 75/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6353\n",
      "Epoch 76/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.5953\n",
      "Epoch 77/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6306\n",
      "Epoch 78/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6235\n",
      "Epoch 79/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6400\n",
      "Epoch 80/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.6471\n",
      "Epoch 81/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6447\n",
      "Epoch 82/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6612\n",
      "Epoch 83/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.5906\n",
      "Epoch 84/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6471\n",
      "Epoch 85/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6353\n",
      "Epoch 86/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.6424\n",
      "Epoch 87/110\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6228 - accuracy: 0.6400\n",
      "Epoch 88/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6259\n",
      "Epoch 89/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.6047\n",
      "Epoch 90/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.5976\n",
      "Epoch 91/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.6188\n",
      "Epoch 92/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6353\n",
      "Epoch 93/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6471\n",
      "Epoch 94/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6588\n",
      "Epoch 95/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6824\n",
      "Epoch 96/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6612\n",
      "Epoch 97/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6659\n",
      "Epoch 98/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6565\n",
      "Epoch 99/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.6353\n",
      "Epoch 100/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6024\n",
      "Epoch 101/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6259\n",
      "Epoch 102/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6729\n",
      "Epoch 103/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6518\n",
      "Epoch 104/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6447\n",
      "Epoch 105/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6518\n",
      "Epoch 106/110\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6214 - accuracy: 0.6447\n",
      "Epoch 107/110\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.6353\n",
      "Epoch 108/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6165\n",
      "Epoch 109/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6353\n",
      "Epoch 110/110\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd9cb08ee50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x), np.array(y), epochs=110) # verbose : 진행상황 출력 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.29756700e-02,  1.40673697e-01, -1.24055028e-01,\n",
       "        -3.37925404e-02, -1.40761882e-01, -5.06848991e-02,\n",
       "        -2.15082485e-02,  7.94979781e-02,  2.11941898e-02,\n",
       "        -7.06144720e-02,  8.69162381e-02, -3.39378640e-02,\n",
       "         1.34140670e-01,  5.21346182e-02, -1.23129323e-01,\n",
       "        -1.39742009e-02, -1.20502412e-01,  1.29512936e-01,\n",
       "        -8.53521451e-02, -1.02104276e-01, -5.17840311e-03,\n",
       "        -1.39209434e-01,  1.30625516e-01,  1.09559774e-01,\n",
       "         6.13160133e-02, -5.70994318e-02, -1.49214685e-01,\n",
       "        -7.97191933e-02,  4.70412672e-02,  1.48652829e-02,\n",
       "         9.45547223e-02,  1.36970997e-01,  1.20001048e-01,\n",
       "         6.31569177e-02, -6.14385232e-02,  3.27882469e-02,\n",
       "        -1.48674309e-01, -9.52510983e-02,  3.83203775e-02,\n",
       "         1.02968842e-01,  1.48355663e-01,  1.42428756e-01,\n",
       "        -4.19301093e-02,  5.39388657e-02, -2.38738162e-03,\n",
       "        -3.78116108e-02, -1.08201280e-01,  1.04814708e-01,\n",
       "         9.54710841e-02,  1.03299707e-01, -1.26853943e-01,\n",
       "         1.02493614e-01,  1.52188390e-01,  7.41614997e-02,\n",
       "        -1.02950886e-01,  7.60503411e-02, -1.49718681e-02,\n",
       "         1.04731113e-01, -1.10840742e-02,  3.88293825e-02,\n",
       "        -2.39389073e-02,  1.32003546e-01, -1.30106568e-01,\n",
       "         1.19123816e-01, -8.28486159e-02,  1.52235981e-02,\n",
       "         8.94891769e-02,  6.33825511e-02,  1.04985246e-02,\n",
       "         1.40722185e-01,  8.19738507e-02, -1.24184072e-01,\n",
       "        -3.39285508e-02,  8.13819375e-03,  9.35653597e-02,\n",
       "         3.81367207e-02, -3.74167338e-02,  1.31354153e-01,\n",
       "        -3.82771716e-02,  5.98477870e-02, -4.33777571e-02,\n",
       "         7.55385756e-02, -3.64589244e-02, -1.47468388e-01,\n",
       "         1.22523308e-01, -4.57469188e-03, -1.13126792e-01,\n",
       "        -9.41999406e-02, -1.45910934e-01,  3.28767952e-03,\n",
       "        -1.45702198e-01, -3.44406441e-03,  1.00399047e-01,\n",
       "        -1.27258301e-01, -2.01056302e-02, -6.08232170e-02,\n",
       "         3.54967862e-02,  1.45563781e-01,  3.86598706e-02,\n",
       "         3.86242718e-02,  4.32872176e-02,  3.45781259e-02,\n",
       "         3.99723947e-02, -6.56470880e-02,  2.38908920e-02,\n",
       "        -1.28562972e-01, -6.81070685e-02, -5.33373207e-02,\n",
       "        -1.32478222e-01, -3.81317027e-02,  3.10095735e-02,\n",
       "         1.32128507e-01,  3.85191329e-02, -6.74103647e-02,\n",
       "         9.76610035e-02,  1.29897654e-01, -1.01427503e-01,\n",
       "         2.41899844e-02, -5.02932817e-02, -9.04791206e-02,\n",
       "        -5.55389514e-03, -4.78715450e-02,  3.90256271e-02,\n",
       "        -7.66509473e-02,  1.13051981e-01, -6.63323374e-03,\n",
       "         3.36739197e-02, -8.92085284e-02,  1.00325942e-01,\n",
       "         3.24638700e-03,  1.12948030e-01, -3.08547076e-03,\n",
       "         9.99584496e-02, -4.20438722e-02, -4.12105918e-02,\n",
       "        -6.95281476e-02, -1.28995389e-01, -3.45294140e-02,\n",
       "        -9.62021053e-02,  9.68861300e-03,  9.70115885e-03,\n",
       "        -1.34667486e-01,  7.61639625e-02,  8.93536508e-02,\n",
       "        -1.28315240e-01,  1.09502643e-01,  3.63952070e-02,\n",
       "         6.86825216e-02, -4.59258854e-02,  6.29104823e-02,\n",
       "         1.43052578e-01, -1.18079737e-01,  1.37209386e-01,\n",
       "         3.85118276e-02, -3.57255116e-02,  7.43200779e-02,\n",
       "        -6.74128253e-03, -1.81926154e-02,  4.85992432e-02,\n",
       "        -5.77712655e-02,  9.56472903e-02,  1.73819419e-02,\n",
       "         7.56472498e-02, -9.48337466e-02, -1.23081869e-02,\n",
       "        -1.31528033e-02, -7.31931180e-02,  1.20242620e-02,\n",
       "        -2.89329956e-03, -1.41729936e-01,  1.07981086e-01,\n",
       "        -9.66455117e-02,  1.32377386e-01,  7.98845589e-02,\n",
       "        -1.71550345e-02,  7.83712268e-02,  1.51316244e-02,\n",
       "         9.31741204e-03,  1.41942561e-01,  1.33422077e-01,\n",
       "        -4.77861986e-02,  1.51305974e-01, -8.40336829e-02,\n",
       "         8.20762217e-02, -1.43283591e-01, -1.28949862e-02,\n",
       "        -1.00850046e-01,  3.55236903e-02,  1.35275781e-01,\n",
       "        -1.36053592e-01,  4.04934585e-02, -1.43336486e-02,\n",
       "         1.51322186e-01, -7.34627023e-02,  1.16279155e-01,\n",
       "        -1.39508381e-01, -3.75411361e-02, -1.04497775e-01,\n",
       "         6.05216622e-02,  5.32817245e-02,  3.29253376e-02,\n",
       "        -3.86543721e-02,  1.39726400e-01,  7.35823065e-02,\n",
       "         1.14241540e-01, -9.81191397e-02,  7.45402426e-02,\n",
       "         8.05338323e-02,  2.78153848e-02,  1.35640919e-01,\n",
       "        -1.02984518e-01,  6.80616647e-02,  4.49282080e-02,\n",
       "         4.61569279e-02, -1.32202834e-01,  3.60726714e-02,\n",
       "         1.47662554e-02,  8.19239616e-02, -6.70783669e-02,\n",
       "         3.64123620e-02, -8.93143415e-02,  5.20069152e-02,\n",
       "        -1.06056064e-01,  4.91971523e-02,  7.45888352e-02,\n",
       "        -8.30196813e-02,  1.22555226e-01, -1.94139685e-02,\n",
       "        -9.46320966e-02,  1.19547099e-01, -7.24706501e-02,\n",
       "         3.68374661e-02, -3.65127847e-02, -1.05052553e-01,\n",
       "         7.46471137e-02,  8.66801888e-02, -9.91733931e-03,\n",
       "        -8.98698866e-02, -3.53457853e-02, -7.63997482e-03,\n",
       "         9.64043438e-02,  6.56455308e-02,  1.01691782e-01,\n",
       "        -8.65352079e-02,  1.38465554e-01,  1.23706544e-02,\n",
       "        -1.40362889e-01, -8.94349292e-02, -7.24866288e-03,\n",
       "        -1.21712297e-01,  2.22177804e-02, -6.02932274e-02,\n",
       "         1.34559214e-01,  5.66419363e-02,  1.36070818e-01,\n",
       "        -1.50377363e-01],\n",
       "       [-3.47951017e-02, -4.67984676e-02,  8.93945098e-02,\n",
       "        -8.93162861e-02, -9.92228463e-02,  6.66925907e-02,\n",
       "         9.07333642e-02, -8.48368853e-02,  1.85213849e-01,\n",
       "         7.07320422e-02,  4.82371897e-02,  3.92139395e-04,\n",
       "        -7.03741014e-02,  6.89835697e-02, -1.01699486e-01,\n",
       "        -7.85111338e-02,  1.35979921e-01, -8.56522471e-02,\n",
       "         9.16550756e-02,  5.23551404e-02,  7.90728927e-02,\n",
       "         7.50070810e-03,  5.98484427e-02, -4.22487929e-02,\n",
       "         8.03350359e-02,  9.60091203e-02,  1.36887699e-01,\n",
       "         9.19642150e-02,  8.24411213e-03,  1.92368209e-01,\n",
       "        -3.63296792e-02, -1.37603283e-01,  6.67974204e-02,\n",
       "        -7.24296868e-02, -1.11653507e-02, -6.00636974e-02,\n",
       "         2.41605937e-02,  5.11613339e-02, -1.34147406e-01,\n",
       "        -1.47960708e-01,  1.13470882e-01, -1.09030902e-02,\n",
       "        -7.09725693e-02,  1.49246037e-01, -3.93646695e-02,\n",
       "         2.41387729e-02, -5.48624396e-02, -4.13374901e-02,\n",
       "        -7.13635013e-02,  8.19906592e-03, -1.47634149e-01,\n",
       "         1.51436746e-01,  7.43922293e-02, -1.07362516e-01,\n",
       "        -9.92299616e-02, -2.57947296e-02, -2.64515914e-02,\n",
       "        -2.62646973e-02,  6.33865269e-03, -1.31741866e-01,\n",
       "        -8.07299018e-02, -1.23997808e-01, -1.28707945e-01,\n",
       "         1.02761090e-01, -3.63584906e-02,  1.58790629e-02,\n",
       "         1.35982186e-02,  9.60240811e-02,  2.07382277e-01,\n",
       "        -6.86677545e-02,  9.14881229e-02, -1.45410910e-01,\n",
       "        -8.95797685e-02,  1.69250697e-01, -4.54870835e-02,\n",
       "         3.42320651e-02,  2.01702397e-02, -1.31304085e-01,\n",
       "         9.30264741e-02, -5.47208786e-02, -4.13391590e-02,\n",
       "         9.64741260e-02, -1.02302864e-01, -3.85926440e-02,\n",
       "         1.22248173e-01, -6.62276074e-02,  8.34353268e-02,\n",
       "        -3.39817181e-02, -5.49302250e-02, -1.27814427e-01,\n",
       "        -1.10061854e-01,  5.12074213e-03,  1.46432430e-01,\n",
       "        -9.71733034e-03, -1.39665246e-01, -5.89910224e-02,\n",
       "        -8.04250687e-02, -1.20631419e-01, -6.67856932e-02,\n",
       "        -1.25219330e-01,  8.02742243e-02,  5.71327657e-03,\n",
       "         8.18049014e-02, -1.72112882e-02, -2.30226498e-02,\n",
       "        -5.95890209e-02, -5.77504411e-02, -1.40510038e-01,\n",
       "         1.18569881e-01,  4.49288227e-02,  4.94636260e-02,\n",
       "        -3.94894406e-02, -1.43615857e-01, -7.96886757e-02,\n",
       "         6.41583949e-02,  7.28279054e-02,  8.85286331e-02,\n",
       "        -8.22422206e-02, -2.82253847e-02, -6.34690672e-02,\n",
       "        -3.31721306e-02, -1.42196864e-02, -1.25813097e-01,\n",
       "         1.41813755e-02, -5.76322153e-02,  1.87690094e-01,\n",
       "         1.35734841e-01,  3.58237773e-02,  3.77547443e-02,\n",
       "        -1.18021034e-01,  6.54613972e-03,  1.48647800e-01,\n",
       "         9.01339203e-02,  1.16038561e-01, -1.40556380e-01,\n",
       "         1.80414617e-02, -7.55490586e-02,  3.86429876e-02,\n",
       "        -4.23414037e-02,  2.01804675e-02,  8.06498453e-02,\n",
       "         4.52001542e-02, -1.46340072e-01,  1.16870284e-01,\n",
       "        -1.05093271e-02,  3.64896655e-02, -1.44130755e-02,\n",
       "        -1.50777504e-01,  4.97929305e-02, -1.03641272e-01,\n",
       "        -1.71821117e-02,  5.22528142e-02,  1.26740366e-01,\n",
       "        -1.10848442e-01, -2.47366726e-02,  7.50974119e-02,\n",
       "        -1.95569173e-01, -4.82103899e-02,  1.08080685e-01,\n",
       "        -4.96923923e-03,  1.04407370e-01, -7.83998966e-02,\n",
       "        -1.22949399e-01, -5.88111058e-02,  1.47016153e-01,\n",
       "        -1.29146203e-01,  1.33624971e-01,  1.69301838e-01,\n",
       "         6.33391514e-02,  1.26484126e-01,  8.86937082e-02,\n",
       "        -9.43900645e-03,  2.07533538e-02,  3.13403308e-02,\n",
       "         6.44865073e-03, -6.51655421e-02,  2.99258381e-02,\n",
       "        -1.22005707e-02, -8.54414105e-02,  1.73179805e-02,\n",
       "        -8.71803090e-02,  6.49563372e-02, -6.60107285e-02,\n",
       "        -5.49807400e-02, -4.31370214e-02,  2.50040703e-02,\n",
       "        -9.98076648e-02, -4.76406813e-02, -9.90298688e-02,\n",
       "        -5.06008565e-02,  5.71397841e-02,  2.89537422e-02,\n",
       "        -5.18090054e-02, -1.40868425e-01,  7.07823783e-02,\n",
       "        -1.33018762e-01,  1.44980237e-01,  6.86271787e-02,\n",
       "         1.50826126e-01,  8.62190127e-03,  1.46749556e-01,\n",
       "         9.75099653e-02, -1.10332713e-01, -1.12726606e-01,\n",
       "         5.54630458e-02,  6.19734079e-02, -3.88818309e-02,\n",
       "         2.23430991e-02, -1.14548340e-01,  2.73479819e-02,\n",
       "        -4.80963141e-02, -6.13669977e-02, -4.53006700e-02,\n",
       "         7.00154305e-02,  1.19041979e-01, -7.09072053e-02,\n",
       "        -6.24533370e-02,  4.19031829e-02, -1.43842578e-01,\n",
       "        -1.06658690e-01,  1.31896526e-01,  1.31118149e-01,\n",
       "         9.00739431e-03,  1.30899936e-01,  5.97501695e-02,\n",
       "        -1.26360863e-01,  9.23425555e-02,  3.08472589e-02,\n",
       "         1.10128582e-01,  1.58561021e-02,  1.45739913e-01,\n",
       "        -1.31639257e-01,  4.78606671e-02,  1.00310802e-01,\n",
       "        -6.08296394e-02,  1.74477696e-04, -9.56613198e-02,\n",
       "         1.49589092e-01,  1.01338895e-02,  1.32215098e-01,\n",
       "        -1.03039064e-01, -3.39849144e-02,  8.33876431e-02,\n",
       "        -4.96998206e-02, -1.35572851e-01, -7.93812722e-02,\n",
       "        -1.24712646e-01,  1.02669865e-01,  7.78286085e-02,\n",
       "        -1.00733057e-01,  1.06913835e-01,  1.83169246e-02,\n",
       "         2.17050761e-02, -4.92839590e-02,  3.45402956e-02,\n",
       "        -9.75600481e-02],\n",
       "       [ 2.34198794e-02, -6.94153979e-02, -4.06586081e-02,\n",
       "        -7.35259205e-02, -1.45228356e-02, -4.32274193e-02,\n",
       "        -6.00585602e-02, -1.11865379e-01,  9.52972025e-02,\n",
       "         1.11158043e-01, -9.55622345e-02, -1.49259254e-01,\n",
       "         1.08097136e-01,  8.82171392e-02, -9.54639316e-02,\n",
       "         2.47340515e-01, -8.00024569e-02,  1.24296904e-01,\n",
       "         2.58126259e-02, -1.31999612e-01,  2.20427036e-01,\n",
       "         5.33971190e-03,  2.88488865e-02, -5.60325533e-02,\n",
       "        -1.24144122e-01,  2.90230811e-02, -4.02778685e-02,\n",
       "         5.92497289e-02, -1.37472600e-02,  1.06538884e-01,\n",
       "         1.29409105e-01,  3.20178419e-02, -3.80583778e-02,\n",
       "         8.15742165e-02,  1.39990211e-01,  9.23279487e-03,\n",
       "         5.70685118e-02,  1.41843051e-01,  4.67702299e-02,\n",
       "         4.70346212e-03,  1.10565811e-01, -1.40185058e-02,\n",
       "        -1.46717429e-01,  8.83326828e-02,  3.01573843e-01,\n",
       "         1.08008377e-01, -2.77195647e-02, -3.59587371e-03,\n",
       "         3.72619629e-02, -2.54605114e-02,  6.49123937e-02,\n",
       "        -1.17003903e-01,  1.20678395e-02,  6.52907342e-02,\n",
       "         9.47776437e-02,  2.19639689e-02, -8.69404525e-02,\n",
       "        -1.45838708e-01, -5.85374720e-02, -1.03997432e-01,\n",
       "        -2.35021077e-02,  6.40750378e-02,  7.18398243e-02,\n",
       "         5.68214208e-02,  1.13750458e-01, -5.81105910e-02,\n",
       "        -1.15296245e-01, -7.84899294e-02,  6.25202581e-02,\n",
       "        -1.04441136e-01,  1.48651004e-01,  6.00606203e-02,\n",
       "        -6.66289553e-02,  1.49389893e-01,  7.08889514e-02,\n",
       "         1.01477176e-01,  8.78384858e-02,  2.17862874e-02,\n",
       "         7.89655596e-02,  3.10136676e-02,  9.84214246e-02,\n",
       "        -1.34432316e-02,  1.00527115e-01,  1.09617382e-01,\n",
       "        -7.97412172e-02,  2.85752803e-01,  1.31203711e-01,\n",
       "        -2.66792178e-02, -2.29611248e-02, -3.04547638e-01,\n",
       "         2.91950405e-02,  2.67158598e-01,  7.43633062e-02,\n",
       "        -9.64985043e-02, -1.20707475e-01,  1.37262017e-01,\n",
       "        -3.21031958e-02,  7.07336813e-02, -1.26315400e-01,\n",
       "        -1.15010135e-01,  6.17425442e-02, -8.48992914e-02,\n",
       "        -5.46998680e-02,  1.41498208e-01, -1.10240735e-01,\n",
       "         1.42672926e-01,  7.30179101e-02,  1.04151666e-01,\n",
       "         5.07224649e-02,  1.17197581e-01, -1.15239145e-02,\n",
       "         2.79859602e-02, -1.36993632e-01,  1.21073604e-01,\n",
       "         1.30808353e-01, -4.86749336e-02,  8.12219232e-02,\n",
       "        -4.72418815e-02, -1.13958411e-01, -5.53878248e-02,\n",
       "         2.95525223e-01,  4.02688980e-04, -9.44625512e-02,\n",
       "        -1.06655657e-01, -4.09143344e-02,  2.36746982e-01,\n",
       "         3.83508541e-02, -3.85135710e-02, -1.25671774e-01,\n",
       "        -2.99831510e-01,  9.91832614e-02,  2.51069456e-01,\n",
       "         1.23607278e-01, -9.46404412e-02,  5.74232638e-03,\n",
       "        -2.98622027e-02, -9.15217251e-02, -1.43326104e-01,\n",
       "         7.07471371e-02,  2.42887795e-01,  5.71874380e-02,\n",
       "        -1.38583571e-01, -1.18224025e-01, -1.00878358e-01,\n",
       "        -8.49636048e-02,  1.27968758e-01, -1.57770179e-02,\n",
       "         1.23803377e-01,  1.51221395e-01, -6.02840111e-02,\n",
       "        -7.00565800e-02, -8.64171684e-02,  1.06041521e-01,\n",
       "         1.28655314e-01, -3.68105322e-02,  9.11542773e-03,\n",
       "        -2.07814708e-01, -1.15231633e-01, -1.29796550e-01,\n",
       "         9.18008089e-02, -1.02507733e-01,  1.43702850e-01,\n",
       "        -1.65582895e-02, -1.45425677e-01,  6.31586239e-02,\n",
       "         1.50097292e-02,  4.83210832e-02,  1.44559713e-02,\n",
       "         2.79936373e-01,  5.29435575e-02, -7.88980275e-02,\n",
       "         5.86445779e-02,  9.63595659e-02, -6.42745942e-02,\n",
       "         1.01762429e-01, -1.10895827e-01,  1.65269285e-01,\n",
       "        -1.60007514e-02,  2.45947540e-02, -2.12119222e-02,\n",
       "        -1.18195936e-01, -1.17470421e-01,  1.56087279e-02,\n",
       "         1.51349545e-01, -3.56971323e-02,  1.11078896e-01,\n",
       "         4.75380272e-02,  7.62259364e-02, -6.84422255e-02,\n",
       "        -1.33809164e-01, -8.29493180e-02,  1.27052531e-01,\n",
       "        -4.99522090e-02,  6.72164857e-02, -7.37264082e-02,\n",
       "         5.99551201e-03,  1.47627015e-02,  1.25184208e-02,\n",
       "         8.46437961e-02,  6.24617785e-02,  1.46891803e-01,\n",
       "        -7.55071416e-02,  1.46136761e-01,  9.67643857e-02,\n",
       "        -3.15324441e-02, -1.09020129e-01,  5.39728701e-02,\n",
       "         1.20379001e-01,  2.30184104e-03,  7.76636153e-02,\n",
       "        -1.46028027e-01,  9.61764455e-02, -8.24998170e-02,\n",
       "        -1.24886334e-02, -1.17265135e-02,  5.78390099e-02,\n",
       "        -5.92384003e-02,  4.88600433e-02, -8.74553695e-02,\n",
       "         6.58356622e-02, -5.12414947e-02, -1.16758339e-01,\n",
       "         1.51525885e-02, -7.37556592e-02,  4.31692153e-02,\n",
       "        -9.54693407e-02,  1.29082888e-01,  4.52736905e-03,\n",
       "         1.76077336e-02,  8.52856189e-02, -1.32965460e-01,\n",
       "         5.80273047e-02, -8.20480287e-02, -9.87937376e-02,\n",
       "        -2.84237415e-02, -3.05799171e-02, -1.00983210e-01,\n",
       "        -1.49477512e-01, -5.91418371e-02,  1.13254882e-01,\n",
       "         2.06936896e-02,  2.75355875e-02,  9.06897038e-02,\n",
       "        -1.48120478e-01,  1.14328563e-02, -2.34694690e-01,\n",
       "        -6.95935413e-02,  1.44848883e-01,  2.72477329e-01,\n",
       "         1.28947943e-01, -3.92581783e-02, -8.14624131e-03,\n",
       "        -1.40812978e-01,  1.01652950e-01,  7.11877942e-02,\n",
       "        -1.17515929e-01]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden layer의 가중치 값 출력\n",
    "hidden_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6245999e-03,  0.0000000e+00,  0.0000000e+00, -5.4386433e-04,\n",
       "        0.0000000e+00,  0.0000000e+00,  9.2735395e-02,  0.0000000e+00,\n",
       "        6.0752042e-02,  0.0000000e+00,  0.0000000e+00, -9.2982482e-05,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.8019426e-01,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        4.3284386e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  6.2026009e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.0236741e-05,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        5.2923137e-01, -3.6341262e-05,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "       -1.4398233e-02,  0.0000000e+00, -1.6983294e-01,  5.7537058e-05,\n",
       "       -6.8881586e-02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  1.4696776e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "        1.6160549e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "       -1.9338951e-04,  1.9645049e-01,  0.0000000e+00,  0.0000000e+00,\n",
       "       -5.4326687e-05,  0.0000000e+00, -6.5258908e-05,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00, -1.5570626e-05,  0.0000000e+00,\n",
       "        0.0000000e+00,  5.8951920e-01,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00, -5.6439924e-01,  0.0000000e+00,  2.7398872e-01,\n",
       "        0.0000000e+00,  0.0000000e+00, -1.6788172e-02,  0.0000000e+00,\n",
       "        1.3295248e-03,  0.0000000e+00,  1.8916759e-05,  2.2931625e-03,\n",
       "        0.0000000e+00,  5.1252167e-03,  0.0000000e+00,  0.0000000e+00,\n",
       "        1.8971700e-02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00, -2.4866778e-04,  3.8144749e-02,  0.0000000e+00,\n",
       "        1.1157370e-03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00, -1.5656893e-01,  0.0000000e+00,  0.0000000e+00,\n",
       "        5.8652133e-01,  0.0000000e+00,  5.5151904e-05,  0.0000000e+00,\n",
       "        0.0000000e+00,  5.3749728e-01,  3.7692988e-04,  0.0000000e+00,\n",
       "        0.0000000e+00, -5.4364610e-01,  0.0000000e+00,  2.7212474e-01,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00, -4.2440672e-04,  0.0000000e+00,  2.2267929e-01,\n",
       "        1.6598052e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  2.8425307e-04,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "       -2.7138299e-01, -1.5035892e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  1.5219761e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "        1.7811920e-01,  8.8495389e-02,  0.0000000e+00,  1.5952128e-01,\n",
       "        5.0139600e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  1.3005750e-01,  0.0000000e+00,\n",
       "        1.4420072e-02, -1.2482073e-01,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  1.7392409e-01,  0.0000000e+00,  3.1086380e-04,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.7843792e-02,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "       -1.8896003e-03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        1.6022118e-02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.3643709e-03,\n",
       "       -1.8877643e-01,  0.0000000e+00,  0.0000000e+00,  5.6462304e-04,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.6725374e-02,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  3.1515851e-04,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "       -8.9255236e-02,  0.0000000e+00, -1.4948424e-04,  2.3946720e-01,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00, -2.1686868e-01,  0.0000000e+00,  0.0000000e+00,\n",
       "        2.7898788e-01,  0.0000000e+00,  1.8144907e-02,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden layer의 절편 값 출력\n",
    "hidden_layer.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer의 출력 확인하기\n",
    "intermediate_layer_model = keras.Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "intermediate_output = intermediate_layer_model(np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(425, 256), dtype=float32, numpy=\n",
       "array([[-1.,  1., -1., ...,  1.,  1., -1.],\n",
       "       [-1.,  1., -1., ...,  1.,  1., -1.],\n",
       "       [-1.,  1., -1., ...,  1.,  1., -1.],\n",
       "       ...,\n",
       "       [-1.,  1., -1., ...,  1.,  1., -1.],\n",
       "       [-1.,  1., -1., ...,  1.,  1., -1.],\n",
       "       [-1.,  1., -1., ...,  1.,  1., -1.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c34e8390e776d2ee205b71ed5a6130fee3cef8da5e87e926ce18e14f4a070d72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
